{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b53fa2a",
   "metadata": {},
   "source": [
    "# 💡 faster R-CNN 돌리기  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490a8ee",
   "metadata": {},
   "source": [
    "# ⚽️ 준비하기: 라이브러리 다운로드. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a59b444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.1+cu111\n"
     ]
    }
   ],
   "source": [
    "# 2️⃣MMdetection 다운로드\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48559df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9/index.html\n",
      "Requirement already satisfied: mmcv-full==1.6.0 in /opt/conda/lib/python3.9/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from mmcv-full==1.6.0) (1.21.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from mmcv-full==1.6.0) (8.3.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from mmcv-full==1.6.0) (21.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from mmcv-full==1.6.0) (6.0)\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.9/site-packages (from mmcv-full==1.6.0) (2.4.0)\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.9/site-packages (from mmcv-full==1.6.0) (0.32.0)\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.9/site-packages (from mmcv-full==1.6.0) (4.5.3.56)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->mmcv-full==1.6.0) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "fatal: destination path 'mmdetection' already exists and is not an empty directory.\n",
      "/aiffel/aiffel/mmdetection\n",
      "Obtaining file:///aiffel/aiffel/mmdetection\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from mmdet==2.26.0) (3.4.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from mmdet==2.26.0) (1.21.4)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.9/site-packages (from mmdet==2.26.0) (2.0.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from mmdet==2.26.0) (1.7.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from mmdet==2.26.0) (1.16.0)\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.9/site-packages (from mmdet==2.26.0) (3.1.10)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmdet==2.26.0) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmdet==2.26.0) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmdet==2.26.0) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmdet==2.26.0) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmdet==2.26.0) (3.0.6)\n",
      "Installing collected packages: mmdet\n",
      "  Attempting uninstall: mmdet\n",
      "    Found existing installation: mmdet 2.26.0\n",
      "    Uninstalling mmdet-2.26.0:\n",
      "      Successfully uninstalled mmdet-2.26.0\n",
      "  Running setup.py develop for mmdet\n",
      "Successfully installed mmdet-2.26.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mmcv-full==1.6.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9/index.html\n",
    "\n",
    "!git clone https://github.com/open-mmlab/mmdetection\n",
    "%cd mmdetection\n",
    "\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b80fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# 완디비 설치\n",
    "!pip install -q --upgrade wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fb21a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.26.0\n",
      "0.13.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# MMDetection\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# MMCV\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "# # Weights and Biases\n",
    "import wandb\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e1621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myunjeongdeok\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /aiffel/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완디비 로그인\n",
    "wandb.login(key= 'f8874be2e62d97b00e02f959f8ae21da6d43513d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ff6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmdet.datasets.builder import DATASETS\n",
    "# from mmdet.datasets.coco import CocoDataset\n",
    "\n",
    "# @DATASETS.register_module(force=True)\n",
    "# class Aimmo(CocoDataset):\n",
    "#      CLASSES = ('car', 'truck', 'bus','pedestrian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4b45ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "import cv2\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "# 반드시 아래 Decorator 설정 할것.@DATASETS.register_module() 설정 시 force=True를 입력하지 않으면 Dataset 재등록 불가. \n",
    "@DATASETS.register_module(force=True)\n",
    "class Aimmo(CustomDataset):\n",
    "    CLASSES = ('car', 'truck', 'bus','pedestrian')\n",
    "  \n",
    "  ##### self.data_root: /content/kitti_tiny/ self.ann_file: /content/kitti_tiny/train.txt self.img_prefix: /content/kitti_tiny/training/image_2\n",
    "  #### ann_file: /content/kitti_tiny/train.txt\n",
    "  # annotation에 대한 모든 파일명을 가지고 있는 텍스트 파일을 __init__(self, ann_file)로 입력 받고, 이 self.ann_file이 load_annotations()의 인자로 입력\n",
    "    def load_annotations(self, ann_file):\n",
    "        print('##### self.data_root:', self.data_root, 'self.ann_file:', self.ann_file, 'self.img_prefix:', self.img_prefix)\n",
    "        print('#### ann_file:', ann_file)\n",
    "        cat2label = {k:i for i, k in enumerate(self.CLASSES)}\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        # 포맷 중립 데이터를 담을 list 객체\n",
    "        data_infos = []\n",
    "    \n",
    "        for image_id in image_list:\n",
    "            filename = '{0:}/{1:}.jpeg'.format(self.img_prefix, image_id)\n",
    "            # 원본 이미지의 너비, 높이를 image를 직접 로드하여 구함. \n",
    "            image = cv2.imread(filename)\n",
    "            height, width = 960, 512\n",
    "            # 개별 image의 annotation 정보 저장용 Dict 생성. key값 filename 에는 image의 파일명만 들어감(디렉토리는 제외)\n",
    "            data_info = {'filename': str(image_id) + '.png',\n",
    "                       'width': width, 'height': height}\n",
    "            # 개별 annotation이 있는 서브 디렉토리의 prefix 변환. \n",
    "            label_prefix = self.img_prefix.replace('img', 'label')\n",
    "            # 개별 annotation 파일을 1개 line 씩 읽어서 list 로드 \n",
    "            lines = mmcv.list_from_file(osp.join(label_prefix, str(image_id)+'.txt'))\n",
    "\n",
    "            # 전체 lines를 개별 line별 공백 레벨로 parsing 하여 다시 list로 저장. content는 list의 list형태임.\n",
    "            # ann 정보는 numpy array로 저장되나 텍스트 처리나 데이터 가공이 list 가 편하므로 일차적으로 list로 변환 수행.   \n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            # 오브젝트의 클래스명은 bbox_names로 저장. \n",
    "            bbox_names = [x[0] for x in content]\n",
    "            # bbox 좌표를 저장\n",
    "            bboxes = [ [float(info) for info in x[1:5]] for x in content]\n",
    "\n",
    "            # 클래스명이 해당 사항이 없는 대상 Filtering out, 'DontCare'sms ignore로 별도 저장.\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                # 만약 bbox_name이 클래스명에 해당 되면, gt_bboxes와 gt_labels에 추가, 그렇지 않으면 gt_bboxes_ignore, gt_labels_ignore에 추가\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_bboxes.append(bbox)\n",
    "                    # gt_labels에는 class id를 입력\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                else:\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "                    gt_labels_ignore.append(-1)\n",
    "            # 개별 image별 annotation 정보를 가지는 Dict 생성. 해당 Dict의 value값은 모두 np.array임. \n",
    "            data_anno = {\n",
    "              'bboxes': np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels': np.array(gt_labels, dtype=np.compat.long),\n",
    "              'bboxes_ignore': np.array(gt_bboxes_ignore, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels_ignore': np.array(gt_labels_ignore, dtype=np.compat.long)\n",
    "            }\n",
    "\n",
    "            # image에 대한 메타 정보를 가지는 data_info Dict에 'ann' key값으로 data_anno를 value로 저장. \n",
    "            data_info.update(ann=data_anno)\n",
    "            # 전체 annotation 파일들에 대한 정보를 가지는 data_infos에 data_info Dict를 추가\n",
    "            data_infos.append(data_info)\n",
    "        # print(f'data_infos이다{data_infos}')\n",
    "#         print(f'data_infos입니다{data_infos}',sep='\\n')\n",
    "#         print(f'bboxes입니다{bboxes}')\n",
    "#         print(f'gt_labels입니다{gt_labels}')\n",
    "        return data_infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60c08f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/mmdetection'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b380810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/aiffel/aiffel/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n",
    "checkpoint_file = '/aiffel/aiffel/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40ffa1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\n",
      "--2022-12-05 03:31:47--  http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.59\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.59|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 167287506 (160M) [application/octet-stream]\n",
      "Saving to: ‘/aiffel/aiffel/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’\n",
      "\n",
      "/aiffel/aiffel/mmde 100%[===================>] 159.54M  10.6MB/s    in 15s     \n",
      "\n",
      "2022-12-05 03:32:03 (10.5 MB/s) - ‘/aiffel/aiffel/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’ saved [167287506/167287506]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd /aiffel/aiffel/mmdetection; mkdir checkpoints\n",
    "!wget -O /aiffel/aiffel/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3926af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "cfg = Config.fromfile(config_file)\n",
    "# print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ae7454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/mmdetection\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52136a37",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10eadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import set_random_seed\n",
    "import copy\n",
    "import os.path as osp\n",
    "import cv2\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "\n",
    "# dataset에 대한 환경 파라미터 수정.\n",
    "cfg.dataset_type = 'Aimmo'\n",
    "\n",
    "\n",
    "cfg.data_root = '/aiffel/aiffel/aimmo/'\n",
    "\n",
    "# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \n",
    "cfg.data.train.type = 'Aimmo'\n",
    "cfg.data.train.data_root = '/aiffel/aiffel/aimmo/'\n",
    "cfg.data.train.ann_file = 'train.txt'\n",
    "cfg.data.train.img_prefix = 'img'\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'Aimmo'\n",
    "cfg.data.val.data_root = '/aiffel/aiffel/aimmo/'\n",
    "cfg.data.val.ann_file = 'val.txt'\n",
    "cfg.data.val.img_prefix = 'img'\n",
    "\n",
    "\n",
    "cfg.data.test.type = 'Aimmo'\n",
    "cfg.data.test.data_root = '/aiffel/aiffel/aimmo/'\n",
    "cfg.data.test.ann_file = 'test.txt'\n",
    "cfg.data.test.img_prefix = 'img'\n",
    "\n",
    "\n",
    "\n",
    "# class의 갯수 수정. \n",
    "cfg.model.roi_head.bbox_head.num_classes = 4\n",
    "\n",
    "# pretrained 모델\n",
    "cfg.load_from = '/aiffel/aiffel/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "\n",
    "# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \n",
    "cfg.work_dir = '/aiffel/aiffel/03_epoch3_/'\n",
    "\n",
    "# 에포크 체크포인트 = 이어서 학습하기\n",
    "# cfg.resume_from = '/aiffel/aiffel/03_epoch3_/epoch_1.pth'\n",
    "\n",
    "# 학습율 변경 환경 파라미터 설정. \n",
    "cfg.optimizer.lr = 0.02 / 8\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 3\n",
    "# cfg.optimizer =  dict(type='Adam', lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "# CustomDataset은 'mAP'이고 CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "cfg.evaluation.interval = 1 # \n",
    "cfg.checkpoint_config.interval = 1\n",
    "\n",
    "\n",
    "# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정. \n",
    "cfg.lr_config.policy='step'\n",
    "\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "# ConfigDict' object has no attribute 'device 오류 발생시 반드시 설정 필요. https://github.com/open-mmlab/mmdetection/issues/7901\n",
    "cfg.device='cuda'\n",
    "\n",
    "cfg.data.samples_per_gpu = 2 # Batch size of a single GPU used in testing\n",
    "cfg.data.workers_per_gpu = 2 # Worker to pre-fetch data for each single GPU\n",
    "cfg.runner.max_epochs = 50 # 에포크 수\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee1102a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=4,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'Aimmo'\n",
      "data_root = '/aiffel/aiffel/aimmo/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(960, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(960, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='train.txt',\n",
      "        img_prefix='img',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(960, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root='/aiffel/aiffel/aimmo/'),\n",
      "    val=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='val.txt',\n",
      "        img_prefix='img',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(960, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/aiffel/aiffel/aimmo/'),\n",
      "    test=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='test.txt',\n",
      "        img_prefix='img',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(960, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/aiffel/aiffel/aimmo/'))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup=None,\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=50)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=3, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '/aiffel/aiffel/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "work_dir = '/aiffel/aiffel/03_epoch3_/'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 수정된 모델 확인\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f453fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.log_config.hooks = [\n",
    "    dict(type='TextLoggerHook'),\n",
    "    dict(type='WandbLoggerHook',\n",
    "         init_kwargs={'project': 'Faster R-CNN',\n",
    "                      'entity': 'aimmoya',\n",
    "                      'name': '에포크 50, 성공해주세요ㅠㅠ',\n",
    "                      'tags': ['Faster R-CNN', 'epoch50', 'default']})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8bb1ac7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### self.data_root: /aiffel/aiffel/aimmo/ self.ann_file: /aiffel/aiffel/aimmo/train.txt self.img_prefix: /aiffel/aiffel/aimmo/img\n",
      "#### ann_file: /aiffel/aiffel/aimmo/train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/mmdetection/mmdet/datasets/custom.py:181: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "# train용 Dataset 생성. \n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d3a3ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aimmo Train dataset with number of images 8000, and instance counts: \n",
      "+----------+-------+-----------+-------+----------+-------+----------------+-------+---------------+-------+\n",
      "| category | count | category  | count | category | count | category       | count | category      | count |\n",
      "+----------+-------+-----------+-------+----------+-------+----------------+-------+---------------+-------+\n",
      "| 0 [car]  | 43095 | 1 [truck] | 8863  | 2 [bus]  | 5423  | 3 [pedestrian] | 16381 | -1 background | 0     |\n",
      "+----------+-------+-----------+-------+----------+-------+----------------+-------+---------------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['ann_file', 'data_root', 'img_prefix', 'seg_prefix', 'seg_suffix', 'proposal_file', 'test_mode', 'filter_empty_gt', 'file_client', 'CLASSES', 'data_infos', 'proposals', 'flag', 'pipeline'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datasets[0])\n",
    "# datasets[0].__sdict__ 로 모든 self variables의 key와 value값을 볼 수 있음. \n",
    "datasets[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf912095",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(datasets[0].data_infos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "print(model.CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c050a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 주의, config에 pretrained 모델 지정이 상대 경로로 설정됨 cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "# 아래와 같이 %cd mmdetection 지정 필요. \n",
    " \n",
    "%cd /aiffel/aiffel/mmdetection\n",
    "\n",
    "# Create work_dir\n",
    "# mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# epochs는 config의 runner 파라미터로 지정됨. 기본 12회, 현재는 50으로 맞췄다. \n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ad05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad4b13",
   "metadata": {},
   "source": [
    "## 테스트 데이터 세트에 Inference 및 Evaluation 적용하기\n",
    "* 런타임 다시 시작 수행 필요(버그?)\n",
    "* tools/test.py 스크립트는 colab에서 오류 발생\n",
    "* 테스트용 Dataset과 DataLoader생성하고 single_gpu_test()를 호출하여 inference 결과를 반환. batch_size를 1로 설정하지 않으면 single_gpu_test() 오류 발생. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc518c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import set_random_seed\n",
    "import copy\n",
    "import os.path as osp\n",
    "import cv2\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "\n",
    "# dataset에 대한 환경 파라미터 수정. \n",
    "cfg.dataset_type = 'Aimmo'\n",
    "\n",
    "\n",
    "cfg.data_root = '/aiffel/aiffel/aimmo/'\n",
    "\n",
    "# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \n",
    "cfg.data.train.type = 'Aimmo'\n",
    "cfg.data.train.data_root = '/aiffel/aiffel/aimmo/'\n",
    "cfg.data.train.ann_file = 'train.txt'\n",
    "cfg.data.train.img_prefix = 'img'\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'Aimmo'\n",
    "cfg.data.val.data_root = '/aiffel/aiffel/aimmo/'\n",
    "cfg.data.val.ann_file = 'val.txt'\n",
    "cfg.data.val.img_prefix = 'img'\n",
    "\n",
    "\n",
    "cfg.data.test.type = 'Aimmo'\n",
    "cfg.data.test.data_root = '/aiffel/aiffel/aimmo/'\n",
    "cfg.data.test.ann_file = 'test.txt'\n",
    "cfg.data.test.img_prefix = 'img'\n",
    "\n",
    "\n",
    "\n",
    "# class의 갯수 수정. \n",
    "cfg.model.roi_head.bbox_head.num_classes = 4\n",
    "\n",
    "# pretrained 모델\n",
    "cfg.load_from = '/aiffel/aiffel/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "\n",
    "# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \n",
    "cfg.work_dir = '/aiffel/aiffel/03_epoch3_/'\n",
    "\n",
    "# 에포크 체크포인트 = 이어서 학습하기\n",
    "# cfg.resume_from = '/aiffel/aiffel/03_epoch3_/epoch_1.pth'\n",
    "\n",
    "# 학습율 변경 환경 파라미터 설정. \n",
    "cfg.optimizer.lr = 0.02 / 8\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 3\n",
    "# cfg.optimizer =  dict(type='Adam', lr=0.0003, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "# CustomDataset은 'mAP'이고 CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "cfg.evaluation.interval = 1 # \n",
    "cfg.checkpoint_config.interval = 1\n",
    "\n",
    "\n",
    "# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정. \n",
    "cfg.lr_config.policy='step'\n",
    "\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "# ConfigDict' object has no attribute 'device 오류 발생시 반드시 설정 필요. https://github.com/open-mmlab/mmdetection/issues/7901\n",
    "cfg.device='cuda'\n",
    "\n",
    "cfg.data.samples_per_gpu = 1 # Batch size of a single GPU used in testing\n",
    "cfg.data.workers_per_gpu = 1 # Worker to pre-fetch data for each single GPU\n",
    "cfg.runner.max_epochs = 50 # 에포크 수\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07182bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dump('/aiffel/aiffel/03_epoch3_/aimmo_faster_rcnn_conf.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfc4fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### self.data_root: /aiffel/aiffel/aimmo/ self.ann_file: /aiffel/aiffel/aimmo/test.txt self.img_prefix: /aiffel/aiffel/aimmo/img\n",
      "#### ann_file: /aiffel/aiffel/aimmo/test.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'img_metas': [DataContainer([[{'filename': '/aiffel/aiffel/aimmo/img/1654752843340_FR-View-CMR-Wide.png', 'ori_filename': '1654752843340_FR-View-CMR-Wide.png', 'ori_shape': (512, 960, 3), 'img_shape': (512, 960, 3), 'pad_shape': (512, 960, 3), 'scale_factor': array([1., 1., 1., 1.], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}}]])],\n",
       " 'img': [tensor([[[[-0.2684, -0.2513, -0.2684,  ...,  0.3652, -0.0116, -0.4226],\n",
       "            [-0.3883, -0.3712, -0.3027,  ...,  0.3309, -0.0972, -0.5938],\n",
       "            [-0.3712, -0.3883, -0.3198,  ...,  0.2453, -0.4226, -0.9363],\n",
       "            ...,\n",
       "            [-1.7925, -1.8097, -1.8268,  ..., -1.4329, -1.4843, -1.5185],\n",
       "            [-1.8439, -1.8439, -1.8268,  ..., -1.4329, -1.5014, -1.5357],\n",
       "            [-1.8610, -1.8268, -1.7925,  ..., -1.4329, -1.4329, -1.5014]],\n",
       "  \n",
       "           [[ 0.0826,  0.1001,  0.0826,  ...,  0.5553,  0.1352, -0.3375],\n",
       "            [-0.0399, -0.0049,  0.0476,  ...,  0.4153, -0.0399, -0.5826],\n",
       "            [-0.0574, -0.0749,  0.0301,  ...,  0.2927, -0.4251, -0.9503],\n",
       "            ...,\n",
       "            [-1.6681, -1.7206, -1.7031,  ..., -1.2304, -1.3179, -1.3179],\n",
       "            [-1.7906, -1.7556, -1.7206,  ..., -1.1604, -1.2654, -1.3004],\n",
       "            [-1.7556, -1.7381, -1.7556,  ..., -1.1254, -1.1954, -1.2654]],\n",
       "  \n",
       "           [[ 0.6008,  0.6008,  0.5834,  ...,  0.8971,  0.7402,  0.5485],\n",
       "            [ 0.5311,  0.4962,  0.5485,  ...,  0.8622,  0.5834,  0.3219],\n",
       "            [ 0.5136,  0.4788,  0.5311,  ...,  0.7925,  0.3045,  0.1128],\n",
       "            ...,\n",
       "            [-1.3339, -1.3687, -1.3513,  ..., -1.2467, -1.2641, -1.2467],\n",
       "            [-1.3513, -1.3164, -1.3513,  ..., -1.1944, -1.1944, -1.2467],\n",
       "            [-1.4210, -1.3687, -1.3861,  ..., -1.0898, -1.1421, -1.1944]]]])]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "\n",
    "# test용 Dataset과 DataLoader 생성. \n",
    "# build_dataset()호출 시 list로 감싸지 않는 것이 train용 dataset 생성시와 차이. \n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n",
    "        samples_per_gpu=cfg.data.samples_per_gpu,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "\n",
    "# 반드시 아래 코드에서 'img' 키값이 tensor로 출력되어야 함. \n",
    "next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f401f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /aiffel/aiffel/weight_default_에폭 50/epoch_49.pth\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "checkpoint_file = '/aiffel/aiffel/weight_default_에폭 50/epoch_49.pth' \n",
    "\n",
    "# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n",
    "model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b062345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/400, elapsed: 0s, ETA:"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_911/3632756478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# single_gpu_test() 를 호출하여 test데이터 세트의 interence 수행. 반드시 batch size는 1이 되어야 함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 위에서 만든 /content/show_test_output 디렉토리에 interence 결과가 시각화된 이미지가 저장됨.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_gpu_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/aiffel/aiffel/abc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/aiffel/mmdetection/mmdet/apis/test.py\u001b[0m in \u001b[0;36msingle_gpu_test\u001b[0;34m(model, data_loader, show, out_dir, show_score_thr)\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 model.module.show_result(\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0mimg_show\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aiffel/mmdetection/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mshow_result\u001b[0;34m(self, img, result, score_thr, bbox_color, text_color, mask_color, thickness, font_size, win_name, show, wait_time, out_file)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mshow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# draw bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         img = imshow_det_bboxes(\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aiffel/mmdetection/mmdet/core/visualization/image.py\u001b[0m in \u001b[0;36mimshow_det_bboxes\u001b[0;34m(img, bboxes, labels, segms, class_names, score_thr, bbox_color, text_color, mask_color, thickness, font_size, win_name, show, wait_time, out_file)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mscales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_adaptive_scales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mareas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         draw_labels(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_bboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aiffel/mmdetection/mmdet/core/visualization/image.py\u001b[0m in \u001b[0;36mdraw_labels\u001b[0;34m(ax, labels, positions, scores, class_names, color, font_size, scales, horizontal_alignment)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_color\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfont_size_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mverticalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'top'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             horizontalalignment=horizontal_alignment)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960.01x512.01 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "model_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n",
    "# single_gpu_test() 를 호출하여 test데이터 세트의 interence 수행. 반드시 batch size는 1이 되어야 함. \n",
    "# 위에서 만든 /content/show_test_output 디렉토리에 interence 결과가 시각화된 이미지가 저장됨. \n",
    "outputs = single_gpu_test(model_ckpt, data_loader, True, '/aiffel/aiffel/abc', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e50a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4c5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f33400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423be65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df8e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e955e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e5ba8102417ed24000ae30d0ee823b0df91ab90972766c536e2f5d51ee26514"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
