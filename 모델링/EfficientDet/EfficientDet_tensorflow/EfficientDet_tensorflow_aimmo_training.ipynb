{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6bb74e8",
   "metadata": {},
   "source": [
    "# 📝 EfficientDet Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e2b0d",
   "metadata": {},
   "source": [
    "## requirement 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6d14fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/EfficientDet/automl/efficientdet\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행 파일이 있는 경로로 이동\n",
    "%cd automl/efficientdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94edef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI (from -r requirements.txt (line 13))\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-sk5_ipjw\n",
      "  Running command git clone --filter=blob:none -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-sk5_ipjw\n",
      "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.6.1 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.6.3)\n",
      "Requirement already satisfied: absl-py>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.3 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.21.4)\n",
      "Requirement already satisfied: Pillow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (8.3.2)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (6.0)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.16.0)\n",
      "Collecting tensorflow>=2.10.0\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "     |████████████████████████████████| 588.3 MB 9.1 kB/s              \n",
      "\u001b[?25hCollecting tensorflow-addons>=0.18.0\n",
      "  Downloading tensorflow_addons-0.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 57.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.11 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (0.12.0)\n",
      "Collecting neural-structured-learning>=1.3.1\n",
      "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
      "     |████████████████████████████████| 128 kB 88.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.29.13 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (0.29.24)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.3->-r requirements.txt (line 3)) (1.3.2)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (59.4.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "     |████████████████████████████████| 2.4 MB 72.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (1.42.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "     |████████████████████████████████| 14.1 MB 72.1 MB/s            \n",
      "\u001b[?25hCollecting absl-py>=0.10.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "     |████████████████████████████████| 124 kB 83.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (0.2.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "     |████████████████████████████████| 6.0 MB 74.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (1.12.1)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 92.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow>=2.10.0->-r requirements.txt (line 8)) (4.0.1)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "     |████████████████████████████████| 439 kB 83.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.9/site-packages (from tensorflow-addons>=0.18.0->-r requirements.txt (line 9)) (2.13.2)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.9/site-packages (from neural-structured-learning>=1.3.1->-r requirements.txt (line 11)) (21.2.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from neural-structured-learning>=1.3.1->-r requirements.txt (line 11)) (1.7.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.10.0->-r requirements.txt (line 8)) (0.37.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (4.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.10.0->-r requirements.txt (line 8)) (3.1.1)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp39-cp39-linux_x86_64.whl size=103741 sha256=2f01babdc49341d56e30d272c1f20585b2767c46f277cc378ec31b63ba8876a4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-93xkj69j/wheels/13/c1/d6/a321055f7089f1a6af654fbf794536b196999f082a9cb68a37\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: absl-py, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, flatbuffers, tensorflow-addons, tensorflow, pycocotools, neural-structured-learning\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.7.0\n",
      "    Uninstalling tensorflow-estimator-2.7.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.7.0\n",
      "    Uninstalling tensorboard-2.7.0:\n",
      "      Successfully uninstalled tensorboard-2.7.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: tensorflow-addons\n",
      "    Found existing installation: tensorflow-addons 0.14.0\n",
      "    Uninstalling tensorflow-addons-0.14.0:\n",
      "      Successfully uninstalled tensorflow-addons-0.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 1.3.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 22.11.23 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-1.3.0 flatbuffers-22.11.23 keras-2.11.0 libclang-14.0.6 neural-structured-learning-1.4.0 pycocotools-2.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.28.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# requirement 설치\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179d8cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 6.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (5.8.0)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "     |████████████████████████████████| 182 kB 71.1 MB/s            \n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (8.0.3)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
      "     |████████████████████████████████| 168 kB 99.1 MB/s            \n",
      "\u001b[?25hCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb) (59.4.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     |████████████████████████████████| 62 kB 2.6 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.8)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "     |████████████████████████████████| 140 kB 82.3 MB/s            \n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=1cea40c39eb355fa31063b3da7436e097e1bd7070e6ab0f7c8c2ca68a554e7a8\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built pathtools\n",
      "Installing collected packages: smmap, urllib3, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.11.1 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 urllib3-1.26.13 wandb-0.13.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# wandb 설치\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1240c",
   "metadata": {},
   "source": [
    "## 학습 진행할 모델 pretrained_ckpt 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211e48a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use model in /aiffel/aiffel/EfficientDet/automl/efficientdet/efficientdet-d2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 학습할 모델\n",
    "MODEL = 'efficientdet-d2' \n",
    "\n",
    "def download(m):\n",
    "    if m not in os.listdir():\n",
    "        !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/{m}.tar.gz\n",
    "        !tar zxf {m}.tar.gz\n",
    "    ckpt_path = os.path.join(os.getcwd(), m)\n",
    "    return ckpt_path\n",
    "\n",
    "# Download checkpoint.\n",
    "ckpt_path = download(MODEL)\n",
    "print('Use model in {}'.format(ckpt_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798dc109",
   "metadata": {},
   "source": [
    "## 모델 config parameter 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c08055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config parameter 작성\n",
    "class TRAIN_CFG:\n",
    "    model_name = 'efficientdet-d2' # efficientdet 모델명\n",
    "    strategy = '' # tpu, 여러개의 GPU들, 단일 GPU 일때 학습 strategy 설정. \n",
    "    model_dir = '/aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt' # 학습된 모델이 저장될 위치\n",
    "    pretrained_ckpt = '/aiffel/aiffel/EfficientDet/automl/efficientdet/efficientdet-d2' # coco로 pretrained된 checkpoint 파일이 있는 디렉토리 위치\n",
    "    pretrain_or_ckpt = 'False'     # True 면 pretrain_ckpt, False 면 이전의 ckpt \n",
    "    hparams = 'num_classes=4,moving_average_decay=0,mixed_precision=true' # 하이퍼파라미터 설정\n",
    "    use_xla = False\n",
    "    use_fake_data = False\n",
    "    # max_instances_per_image를 200으로 설정하고, D2 모델이 상대적으로 더 크기 때문에 batch_size를 8로 설정시 GPU Out of Memory 발생 \n",
    "    batch_size = 4\n",
    "    eval_samples = 2000 # evaluation image 데이터 갯수\n",
    "    steps_per_execution = 1 # train 시 steps 횟수\n",
    "    num_examples_per_epoch = 50 # 1 epochs 시 적용하는 examples 개수 \n",
    "    num_epochs = 100 # epochs 횟수\n",
    "    train_file_pattern = '/aiffel/aiffel/AIFFELTHON/real_dataset/tfrecord/train/train-*.tfrecord' # 학습용 tfrecords를 glob 형태로 가져오는 표현식. \n",
    "    val_file_pattern = '/aiffel/aiffel/AIFFELTHON/real_dataset/tfrecord/val/val-*.tfrecord' # 검증용 tfrecords를 glob 형태로 가져오는 표현식. \n",
    "    val_json_file = None # optional coco validation json \n",
    "    mode = 'traineval' # train만 적용 또는 train과 eval함께 적용(traineval)\n",
    "    num_shards = 100 \n",
    "    max_instances_per_image = 200\n",
    "    image_size = '960x512'\n",
    "    label_map = {\n",
    "    'car' : 0, \n",
    "    'truck' : 1, \n",
    "    'bus' : 2, \n",
    "    'Pedestrian' : 3}\n",
    "    \n",
    "    num_cores = 2 # tpu 일때 8 적용.  \n",
    "    tpu = None\n",
    "    gcp_project = None\n",
    "    tpu_zone = None\n",
    "    eval_master = ''\n",
    "    eval_name = None\n",
    "    tf_random_seed = 2021\n",
    "    profile = False\n",
    "    debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef880be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x7fa5dc074820>\n",
      "act_type: swish\n",
      "alpha: 0.25\n",
      "anchor_scale: 4.0\n",
      "apply_bn_for_resampling: true\n",
      "aspect_ratios:\n",
      "- 1.0\n",
      "- 2.0\n",
      "- 0.5\n",
      "autoaugment_policy: null\n",
      "backbone_config: null\n",
      "backbone_name: efficientnet-b2\n",
      "batch_size: 4\n",
      "box_class_repeats: 3\n",
      "box_loss_weight: 50.0\n",
      "ckpt_var_scope: null\n",
      "clip_gradients_norm: 10.0\n",
      "conv_after_downsample: false\n",
      "conv_bn_act_pattern: false\n",
      "data_format: channels_last\n",
      "dataset_type: null\n",
      "debug: false\n",
      "delta: 0.1\n",
      "drop_remainder: true\n",
      "eval_samples: 2000\n",
      "first_lr_drop_epoch: 200.0\n",
      "fpn_cell_repeats: 5\n",
      "fpn_config: null\n",
      "fpn_name: null\n",
      "fpn_num_filters: 112\n",
      "fpn_weight_method: null\n",
      "gamma: 1.5\n",
      "grad_checkpoint: false\n",
      "grid_mask: false\n",
      "heads:\n",
      "- object_detection\n",
      "image_size: !!python/tuple\n",
      "- 512\n",
      "- 960\n",
      "img_summary_steps: null\n",
      "input_rand_hflip: true\n",
      "iou_loss_type: null\n",
      "iou_loss_weight: 1.0\n",
      "is_training_bn: true\n",
      "jitter_max: 2.0\n",
      "jitter_min: 0.1\n",
      "label_map:\n",
      "    Pedestrian: 3\n",
      "    bus: 2\n",
      "    car: 0\n",
      "    truck: 1\n",
      "label_smoothing: 0.1\n",
      "learning_rate: 0.08\n",
      "loss_scale: null\n",
      "lr_decay_method: cosine\n",
      "lr_warmup_epoch: 1.0\n",
      "lr_warmup_init: 0.008\n",
      "map_freq: 5\n",
      "max_instances_per_image: 200\n",
      "max_level: 7\n",
      "mean_rgb:\n",
      "- 123.675\n",
      "- 116.28\n",
      "- 103.53\n",
      "min_level: 3\n",
      "mixed_precision: true\n",
      "mode: traineval\n",
      "model_dir: /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt\n",
      "model_name: efficientdet-d2\n",
      "momentum: 0.9\n",
      "moving_average_decay: 0\n",
      "name: efficientdet-d2\n",
      "nms_configs:\n",
      "    iou_thresh: null\n",
      "    max_nms_inputs: 0\n",
      "    max_output_size: 100\n",
      "    method: gaussian\n",
      "    pyfunc: false\n",
      "    score_thresh: 0.0\n",
      "    sigma: null\n",
      "num_classes: 4\n",
      "num_epochs: 100\n",
      "num_scales: 3\n",
      "num_shards: 1\n",
      "optimizer: sgd\n",
      "poly_lr_power: 0.9\n",
      "positives_momentum: null\n",
      "pretrain_or_ckpt: 'False'\n",
      "profile: false\n",
      "regenerate_source_id: false\n",
      "sample_image: null\n",
      "save_freq: epoch\n",
      "scale_range: false\n",
      "second_lr_drop_epoch: 250.0\n",
      "seg_num_classes: 3\n",
      "separable_conv: true\n",
      "skip_crowd_during_training: true\n",
      "skip_mismatch: true\n",
      "stddev_rgb:\n",
      "- 58.395\n",
      "- 57.120000000000005\n",
      "- 57.375\n",
      "steps_per_epoch: 12\n",
      "steps_per_execution: 1\n",
      "strategy: ''\n",
      "survival_prob: null\n",
      "target_size: null\n",
      "tf_random_seed: 2021\n",
      "tflite_max_detections: 100\n",
      "use_keras_model: true\n",
      "val_json_file: null\n",
      "var_freeze_expr: null\n",
      "verbose: 1\n",
      "weight_decay: 4.0e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 위에서 작성한 config parameter들을 업데이트\n",
    "from tf2.train import setup_model\n",
    "import hparams_config\n",
    "\n",
    "import utils\n",
    "# from tf2 import tfmot\n",
    "from tf2 import train_lib\n",
    "from tf2 import util_keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = hparams_config.get_detection_config(TRAIN_CFG.model_name)\n",
    "config.override(TRAIN_CFG.hparams)\n",
    "\n",
    "steps_per_epoch = TRAIN_CFG.num_examples_per_epoch // TRAIN_CFG.batch_size\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    ds_strategy = tf.distribute.OneDeviceStrategy('device:GPU:0')\n",
    "else:\n",
    "    ds_strategy = tf.distribute.OneDeviceStrategy('device:CPU:0')\n",
    "\n",
    "print(ds_strategy)\n",
    "\n",
    "params = dict(\n",
    "      profile=TRAIN_CFG.profile,\n",
    "      mode = TRAIN_CFG.mode,\n",
    "      model_name=TRAIN_CFG.model_name,\n",
    "      steps_per_execution=TRAIN_CFG.steps_per_execution,\n",
    "      num_epochs = TRAIN_CFG.num_epochs,\n",
    "      model_dir=TRAIN_CFG.model_dir,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      strategy=TRAIN_CFG.strategy,\n",
    "      batch_size=TRAIN_CFG.batch_size,\n",
    "      tf_random_seed=TRAIN_CFG.tf_random_seed,\n",
    "      debug=TRAIN_CFG.debug,\n",
    "      val_json_file=TRAIN_CFG.val_json_file,\n",
    "      eval_samples=TRAIN_CFG.eval_samples,\n",
    "      num_shards=ds_strategy.num_replicas_in_sync,\n",
    "      max_instances_per_image = TRAIN_CFG.max_instances_per_image,\n",
    "      image_size= TRAIN_CFG.image_size,\n",
    "      pretrain_or_ckpt=TRAIN_CFG.pretrain_or_ckpt,\n",
    "      label_map=TRAIN_CFG.label_map\n",
    "      )\n",
    "\n",
    "config.override(params, True)\n",
    "\n",
    "# image size를 tuple 형태로 변환. 512는 (512, 512)로 '1920x880' 은 (1920, 880) 으로 변환.  \n",
    "config.image_size = utils.parse_image_size(config.image_size)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bbd434",
   "metadata": {},
   "source": [
    "## wandb 로그인 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007de910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /aiffel/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminkikwak\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/EfficientDet/automl/efficientdet/wandb/run-20221203_103326-sloqocrc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/minkikwak/efficinetdet-d2/runs/sloqocrc\" target=\"_blank\">h_default_epoch_100</a></strong> to <a href=\"https://wandb.ai/minkikwak/efficinetdet-d2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "run = wandb.init(project = 'efficinetdet-d2',\n",
    "                 entity = '',\n",
    "                 name = 'h_default_epoch_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5baa1",
   "metadata": {},
   "source": [
    "## 학습할 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efad2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "\n",
    "def get_dataset(is_training, config):\n",
    "    # is_training이 True이면 TRAIN_CFG의 train_file_pattern, 그렇지 아니면 val_file_pattern\n",
    "    file_pattern = (\n",
    "      TRAIN_CFG.train_file_pattern\n",
    "      if is_training else TRAIN_CFG.val_file_pattern)\n",
    "    \n",
    "    if not file_pattern:\n",
    "        raise ValueError('No matching files.')\n",
    "    \n",
    "    return dataloader.InputReader(\n",
    "    file_pattern,\n",
    "    is_training=is_training,\n",
    "    use_fake_data=TRAIN_CFG.use_fake_data,\n",
    "    max_instances_per_image=config.max_instances_per_image,\n",
    "    debug=TRAIN_CFG.debug)(\n",
    "        config.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff11fb",
   "metadata": {},
   "source": [
    "## 학습 진행할 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ccc804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "/tmp/__autograph_generated_fileoe4bu57h.py:23: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  ag__.for_stmt(ag__.ld(self).updates, None, loop_body, get_state, set_state, (), {'iterate_names': 'u'})\n",
      "/aiffel/aiffel/EfficientDet/automl/efficientdet/utils.py:255: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  for u in self.updates:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 ckpt 불러오기!!!\n",
      "Model: \"\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnet-b2 (Model)     multiple                  7267314   \n",
      "                                                                 \n",
      " resample_p6 (ResampleFeatur  multiple                 39984     \n",
      " eMap)                                                           \n",
      "                                                                 \n",
      " resample_p7 (ResampleFeatur  multiple                 0         \n",
      " eMap)                                                           \n",
      "                                                                 \n",
      " fpn_cells (FPNCells)        multiple                  678479    \n",
      "                                                                 \n",
      " class_net (ClassNet)        multiple                  52788     \n",
      "                                                                 \n",
      " box_net (BoxNet)            multiple                  52788     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,091,353\n",
      "Trainable params: 8,009,577\n",
      "Non-trainable params: 81,776\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tf2 import train_lib\n",
    "from tf2 import train\n",
    "\n",
    "def get_efficientdet_model(config):\n",
    "    # 2개의 class를 가진 efficientdet d2 모델을 생성. \n",
    "    model = train_lib.EfficientDetNetTrain(config=config)\n",
    "    model = train.setup_model(model, config)\n",
    "    \n",
    "    # pretrain_ckpt 불러오기\n",
    "    if config.pretrain_or_ckpt == 'True':\n",
    "        ckpt_path = tf.train.latest_checkpoint(TRAIN_CFG.pretrained_ckpt)\n",
    "        # classfication layer를 제외하고 pretrained weight를 생성된 모델로 로딩. \n",
    "        util_keras.restore_ckpt(\n",
    "                model,\n",
    "                ckpt_path,\n",
    "                config.moving_average_decay,\n",
    "                exclude_layers=['class_net'])\n",
    "        print('pretrain ckpt 불러오기!!!')\n",
    "        \n",
    "    # 이전 ckpt 불러오기    \n",
    "    else:\n",
    "        ckpt_path = tf.train.latest_checkpoint(TRAIN_CFG.model_dir)\n",
    "        util_keras.restore_ckpt(\n",
    "                model,\n",
    "                ckpt_path,\n",
    "                config.moving_average_decay)\n",
    "        print('이전 ckpt 불러오기!!!')\n",
    "    train.init_experimental(config)\n",
    "    return model\n",
    "\n",
    "model = get_efficientdet_model(config)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "107760e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traineval\n"
     ]
    }
   ],
   "source": [
    "print(config.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405c83e",
   "metadata": {},
   "source": [
    "## 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b35c5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_steps_per_epoch: 2000 val_steps_per_epoch: 500\n",
      "Epoch 76/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1156 - cls_loss: 0.0499 - box_loss: 0.0013 - reg_l2_loss: 0.0842 - loss: 0.1998 - learning_rate: 0.0021 - gradient_norm: 1.6668\n",
      "Epoch 76: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-76\n",
      "2000/2000 [==============================] - 1303s 597ms/step - det_loss: 0.1156 - cls_loss: 0.0499 - box_loss: 0.0013 - reg_l2_loss: 0.0842 - loss: 0.1998 - learning_rate: 0.0021 - gradient_norm: 1.6669 - val_det_loss: 0.2086 - val_cls_loss: 0.0932 - val_box_loss: 0.0023 - val_reg_l2_loss: 0.0841 - val_loss: 0.2927\n",
      "Epoch 77/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1204 - cls_loss: 0.0528 - box_loss: 0.0014 - reg_l2_loss: 0.0840 - loss: 0.2044 - learning_rate: 0.0021 - gradient_norm: 1.7377\n",
      "Epoch 77: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-77\n",
      "2000/2000 [==============================] - 1186s 593ms/step - det_loss: 0.1204 - cls_loss: 0.0528 - box_loss: 0.0014 - reg_l2_loss: 0.0840 - loss: 0.2044 - learning_rate: 0.0021 - gradient_norm: 1.7375 - val_det_loss: 0.2051 - val_cls_loss: 0.1130 - val_box_loss: 0.0018 - val_reg_l2_loss: 0.0840 - val_loss: 0.2890\n",
      "Epoch 78/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1176 - cls_loss: 0.0512 - box_loss: 0.0013 - reg_l2_loss: 0.0839 - loss: 0.2014 - learning_rate: 0.0025 - gradient_norm: 1.6911\n",
      "Epoch 78: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-78\n",
      "2000/2000 [==============================] - 1186s 593ms/step - det_loss: 0.1176 - cls_loss: 0.0511 - box_loss: 0.0013 - reg_l2_loss: 0.0839 - loss: 0.2014 - learning_rate: 0.0025 - gradient_norm: 1.6906 - val_det_loss: 0.1780 - val_cls_loss: 0.0785 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0838 - val_loss: 0.2619\n",
      "Epoch 79/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1262 - cls_loss: 0.0551 - box_loss: 0.0014 - reg_l2_loss: 0.0837 - loss: 0.2099 - learning_rate: 0.0029 - gradient_norm: 1.8058\n",
      "Epoch 79: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-79\n",
      "2000/2000 [==============================] - 1185s 592ms/step - det_loss: 0.1262 - cls_loss: 0.0551 - box_loss: 0.0014 - reg_l2_loss: 0.0837 - loss: 0.2099 - learning_rate: 0.0029 - gradient_norm: 1.8060 - val_det_loss: 0.1988 - val_cls_loss: 0.1043 - val_box_loss: 0.0019 - val_reg_l2_loss: 0.0837 - val_loss: 0.2825\n",
      "Epoch 80/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1209 - cls_loss: 0.0530 - box_loss: 0.0014 - reg_l2_loss: 0.0836 - loss: 0.2045 - learning_rate: 0.0029 - gradient_norm: 1.7197\n",
      "Epoch 80: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-80\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(200000, 7)\n",
      "0/200000\n",
      "DONE (t=1.88s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=13.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.90s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.549\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.465\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.552\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
      "2000/2000 [==============================] - 1284s 642ms/step - det_loss: 0.1209 - cls_loss: 0.0530 - box_loss: 0.0014 - reg_l2_loss: 0.0836 - loss: 0.2045 - learning_rate: 0.0029 - gradient_norm: 1.7195 - val_det_loss: 0.1956 - val_cls_loss: 0.0885 - val_box_loss: 0.0021 - val_reg_l2_loss: 0.0835 - val_loss: 0.2792\n",
      "Epoch 81/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1184 - cls_loss: 0.0516 - box_loss: 0.0013 - reg_l2_loss: 0.0835 - loss: 0.2019 - learning_rate: 0.0025 - gradient_norm: 1.6683\n",
      "Epoch 81: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-81\n",
      "2000/2000 [==============================] - 1185s 593ms/step - det_loss: 0.1185 - cls_loss: 0.0516 - box_loss: 0.0013 - reg_l2_loss: 0.0835 - loss: 0.2020 - learning_rate: 0.0025 - gradient_norm: 1.6685 - val_det_loss: 0.1816 - val_cls_loss: 0.0922 - val_box_loss: 0.0018 - val_reg_l2_loss: 0.0834 - val_loss: 0.2650\n",
      "Epoch 82/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1167 - cls_loss: 0.0503 - box_loss: 0.0013 - reg_l2_loss: 0.0833 - loss: 0.2000 - learning_rate: 0.0021 - gradient_norm: 1.7112\n",
      "Epoch 82: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-82\n",
      "2000/2000 [==============================] - 1186s 593ms/step - det_loss: 0.1167 - cls_loss: 0.0503 - box_loss: 0.0013 - reg_l2_loss: 0.0833 - loss: 0.2000 - learning_rate: 0.0021 - gradient_norm: 1.7115 - val_det_loss: 0.2166 - val_cls_loss: 0.0944 - val_box_loss: 0.0024 - val_reg_l2_loss: 0.0833 - val_loss: 0.2998\n",
      "Epoch 83/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1185 - cls_loss: 0.0510 - box_loss: 0.0013 - reg_l2_loss: 0.0832 - loss: 0.2017 - learning_rate: 0.0021 - gradient_norm: 1.7176\n",
      "Epoch 83: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-83\n",
      "2000/2000 [==============================] - 1186s 593ms/step - det_loss: 0.1185 - cls_loss: 0.0510 - box_loss: 0.0013 - reg_l2_loss: 0.0832 - loss: 0.2017 - learning_rate: 0.0021 - gradient_norm: 1.7170 - val_det_loss: 0.2060 - val_cls_loss: 0.0960 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0831 - val_loss: 0.2891\n",
      "Epoch 84/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1182 - cls_loss: 0.0518 - box_loss: 0.0013 - reg_l2_loss: 0.0831 - loss: 0.2012 - learning_rate: 0.0024 - gradient_norm: 1.6910\n",
      "Epoch 84: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-84\n",
      "2000/2000 [==============================] - 1186s 593ms/step - det_loss: 0.1182 - cls_loss: 0.0518 - box_loss: 0.0013 - reg_l2_loss: 0.0831 - loss: 0.2012 - learning_rate: 0.0024 - gradient_norm: 1.6916 - val_det_loss: 0.1681 - val_cls_loss: 0.0712 - val_box_loss: 0.0019 - val_reg_l2_loss: 0.0830 - val_loss: 0.2511\n",
      "Epoch 85/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1210 - cls_loss: 0.0527 - box_loss: 0.0014 - reg_l2_loss: 0.0829 - loss: 0.2039 - learning_rate: 0.0028 - gradient_norm: 1.7134\n",
      "Epoch 85: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-85\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(200000, 7)\n",
      "0/200000\n",
      "DONE (t=1.93s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=13.59s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.85s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.551\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.467\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1277s 639ms/step - det_loss: 0.1209 - cls_loss: 0.0527 - box_loss: 0.0014 - reg_l2_loss: 0.0829 - loss: 0.2038 - learning_rate: 0.0028 - gradient_norm: 1.7128 - val_det_loss: 0.2088 - val_cls_loss: 0.1006 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0829 - val_loss: 0.2917\n",
      "Epoch 86/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1199 - cls_loss: 0.0518 - box_loss: 0.0014 - reg_l2_loss: 0.0828 - loss: 0.2027 - learning_rate: 0.0029 - gradient_norm: 1.6774\n",
      "Epoch 86: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-86\n",
      "2000/2000 [==============================] - 1187s 593ms/step - det_loss: 0.1199 - cls_loss: 0.0518 - box_loss: 0.0014 - reg_l2_loss: 0.0828 - loss: 0.2027 - learning_rate: 0.0029 - gradient_norm: 1.6773 - val_det_loss: 0.1893 - val_cls_loss: 0.0837 - val_box_loss: 0.0021 - val_reg_l2_loss: 0.0827 - val_loss: 0.2720\n",
      "Epoch 87/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1171 - cls_loss: 0.0503 - box_loss: 0.0013 - reg_l2_loss: 0.0826 - loss: 0.1998 - learning_rate: 0.0027 - gradient_norm: 1.6788\n",
      "Epoch 87: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-87\n",
      "2000/2000 [==============================] - 1189s 594ms/step - det_loss: 0.1171 - cls_loss: 0.0503 - box_loss: 0.0013 - reg_l2_loss: 0.0826 - loss: 0.1998 - learning_rate: 0.0027 - gradient_norm: 1.6784 - val_det_loss: 0.1896 - val_cls_loss: 0.0902 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0825 - val_loss: 0.2722\n",
      "Epoch 88/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1157 - cls_loss: 0.0498 - box_loss: 0.0013 - reg_l2_loss: 0.0825 - loss: 0.1982 - learning_rate: 0.0022 - gradient_norm: 1.6920\n",
      "Epoch 88: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-88\n",
      "2000/2000 [==============================] - 1189s 594ms/step - det_loss: 0.1157 - cls_loss: 0.0499 - box_loss: 0.0013 - reg_l2_loss: 0.0825 - loss: 0.1982 - learning_rate: 0.0022 - gradient_norm: 1.6923 - val_det_loss: 0.2046 - val_cls_loss: 0.1038 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0824 - val_loss: 0.2871\n",
      "Epoch 89/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1163 - cls_loss: 0.0489 - box_loss: 0.0013 - reg_l2_loss: 0.0824 - loss: 0.1987 - learning_rate: 0.0020 - gradient_norm: 1.6943\n",
      "Epoch 89: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-89\n",
      "2000/2000 [==============================] - 1185s 592ms/step - det_loss: 0.1164 - cls_loss: 0.0490 - box_loss: 0.0013 - reg_l2_loss: 0.0824 - loss: 0.1987 - learning_rate: 0.0021 - gradient_norm: 1.6953 - val_det_loss: 0.2383 - val_cls_loss: 0.1154 - val_box_loss: 0.0025 - val_reg_l2_loss: 0.0823 - val_loss: 0.3206\n",
      "Epoch 90/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1180 - cls_loss: 0.0508 - box_loss: 0.0013 - reg_l2_loss: 0.0822 - loss: 0.2002 - learning_rate: 0.0023 - gradient_norm: 1.7353\n",
      "Epoch 90: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-90\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(200000, 7)\n",
      "0/200000\n",
      "DONE (t=1.81s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=13.44s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.94s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.546\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.466\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.472\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
      "2000/2000 [==============================] - 1278s 639ms/step - det_loss: 0.1180 - cls_loss: 0.0508 - box_loss: 0.0013 - reg_l2_loss: 0.0822 - loss: 0.2002 - learning_rate: 0.0023 - gradient_norm: 1.7351 - val_det_loss: 0.2072 - val_cls_loss: 0.0800 - val_box_loss: 0.0025 - val_reg_l2_loss: 0.0822 - val_loss: 0.2894\n",
      "Epoch 91/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1201 - cls_loss: 0.0514 - box_loss: 0.0014 - reg_l2_loss: 0.0821 - loss: 0.2023 - learning_rate: 0.0027 - gradient_norm: 1.7133\n",
      "Epoch 91: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-91\n",
      "2000/2000 [==============================] - 1185s 592ms/step - det_loss: 0.1201 - cls_loss: 0.0514 - box_loss: 0.0014 - reg_l2_loss: 0.0821 - loss: 0.2022 - learning_rate: 0.0027 - gradient_norm: 1.7132 - val_det_loss: 0.2430 - val_cls_loss: 0.1448 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0821 - val_loss: 0.3251\n",
      "Epoch 92/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1184 - cls_loss: 0.0515 - box_loss: 0.0013 - reg_l2_loss: 0.0820 - loss: 0.2004 - learning_rate: 0.0029 - gradient_norm: 1.7690\n",
      "Epoch 92: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-92\n",
      "2000/2000 [==============================] - 1184s 592ms/step - det_loss: 0.1184 - cls_loss: 0.0515 - box_loss: 0.0013 - reg_l2_loss: 0.0820 - loss: 0.2004 - learning_rate: 0.0029 - gradient_norm: 1.7686 - val_det_loss: 0.2034 - val_cls_loss: 0.1076 - val_box_loss: 0.0019 - val_reg_l2_loss: 0.0819 - val_loss: 0.2853\n",
      "Epoch 93/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1171 - cls_loss: 0.0516 - box_loss: 0.0013 - reg_l2_loss: 0.0818 - loss: 0.1989 - learning_rate: 0.0028 - gradient_norm: 1.7187\n",
      "Epoch 93: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-93\n",
      "2000/2000 [==============================] - 1184s 592ms/step - det_loss: 0.1170 - cls_loss: 0.0516 - box_loss: 0.0013 - reg_l2_loss: 0.0818 - loss: 0.1989 - learning_rate: 0.0028 - gradient_norm: 1.7182 - val_det_loss: 0.1795 - val_cls_loss: 0.1005 - val_box_loss: 0.0016 - val_reg_l2_loss: 0.0818 - val_loss: 0.2612\n",
      "Epoch 94/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1118 - cls_loss: 0.0473 - box_loss: 0.0013 - reg_l2_loss: 0.0817 - loss: 0.1935 - learning_rate: 0.0024 - gradient_norm: 1.6313\n",
      "Epoch 94: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-94\n",
      "2000/2000 [==============================] - 1184s 592ms/step - det_loss: 0.1118 - cls_loss: 0.0474 - box_loss: 0.0013 - reg_l2_loss: 0.0817 - loss: 0.1935 - learning_rate: 0.0024 - gradient_norm: 1.6316 - val_det_loss: 0.2128 - val_cls_loss: 0.1003 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0816 - val_loss: 0.2944\n",
      "Epoch 95/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1149 - cls_loss: 0.0499 - box_loss: 0.0013 - reg_l2_loss: 0.0816 - loss: 0.1964 - learning_rate: 0.0021 - gradient_norm: 1.7062\n",
      "Epoch 95: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-95\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(200000, 7)\n",
      "0/200000\n",
      "DONE (t=1.92s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=14.38s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.82s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.549\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.465\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1277s 638ms/step - det_loss: 0.1149 - cls_loss: 0.0499 - box_loss: 0.0013 - reg_l2_loss: 0.0816 - loss: 0.1964 - learning_rate: 0.0021 - gradient_norm: 1.7061 - val_det_loss: 0.1874 - val_cls_loss: 0.0892 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0815 - val_loss: 0.2689\n",
      "Epoch 96/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1157 - cls_loss: 0.0491 - box_loss: 0.0013 - reg_l2_loss: 0.0814 - loss: 0.1971 - learning_rate: 0.0022 - gradient_norm: 1.7239\n",
      "Epoch 96: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-96\n",
      "2000/2000 [==============================] - 1188s 594ms/step - det_loss: 0.1157 - cls_loss: 0.0491 - box_loss: 0.0013 - reg_l2_loss: 0.0814 - loss: 0.1971 - learning_rate: 0.0022 - gradient_norm: 1.7246 - val_det_loss: 0.2159 - val_cls_loss: 0.1073 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0814 - val_loss: 0.2972\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1137 - cls_loss: 0.0498 - box_loss: 0.0013 - reg_l2_loss: 0.0813 - loss: 0.1950 - learning_rate: 0.0026 - gradient_norm: 1.6823\n",
      "Epoch 97: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-97\n",
      "2000/2000 [==============================] - 1185s 593ms/step - det_loss: 0.1137 - cls_loss: 0.0498 - box_loss: 0.0013 - reg_l2_loss: 0.0813 - loss: 0.1950 - learning_rate: 0.0026 - gradient_norm: 1.6821 - val_det_loss: 0.1888 - val_cls_loss: 0.0831 - val_box_loss: 0.0021 - val_reg_l2_loss: 0.0812 - val_loss: 0.2700\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1157 - cls_loss: 0.0491 - box_loss: 0.0013 - reg_l2_loss: 0.0811 - loss: 0.1968 - learning_rate: 0.0029 - gradient_norm: 1.6896\n",
      "Epoch 98: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-98\n",
      "2000/2000 [==============================] - 1185s 592ms/step - det_loss: 0.1157 - cls_loss: 0.0491 - box_loss: 0.0013 - reg_l2_loss: 0.0811 - loss: 0.1968 - learning_rate: 0.0029 - gradient_norm: 1.6897 - val_det_loss: 0.1991 - val_cls_loss: 0.1058 - val_box_loss: 0.0019 - val_reg_l2_loss: 0.0811 - val_loss: 0.2802\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1148 - cls_loss: 0.0499 - box_loss: 0.0013 - reg_l2_loss: 0.0810 - loss: 0.1958 - learning_rate: 0.0029 - gradient_norm: 1.6872\n",
      "Epoch 99: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-99\n",
      "2000/2000 [==============================] - 1183s 592ms/step - det_loss: 0.1149 - cls_loss: 0.0499 - box_loss: 0.0013 - reg_l2_loss: 0.0810 - loss: 0.1959 - learning_rate: 0.0029 - gradient_norm: 1.6876 - val_det_loss: 0.1793 - val_cls_loss: 0.1088 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0809 - val_loss: 0.2603\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - ETA: 0s - det_loss: 0.1118 - cls_loss: 0.0480 - box_loss: 0.0013 - reg_l2_loss: 0.0809 - loss: 0.1927 - learning_rate: 0.0025 - gradient_norm: 1.6878\n",
      "Epoch 100: saving model to /aiffel/aiffel/EfficientDet/efficientdet-d2_ckpt/ckpt-100\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(200000, 7)\n",
      "0/200000\n",
      "DONE (t=1.96s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=14.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.86s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.461\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n",
      "2000/2000 [==============================] - 1278s 639ms/step - det_loss: 0.1118 - cls_loss: 0.0480 - box_loss: 0.0013 - reg_l2_loss: 0.0809 - loss: 0.1927 - learning_rate: 0.0025 - gradient_norm: 1.6877 - val_det_loss: 0.1657 - val_cls_loss: 0.0762 - val_box_loss: 0.0018 - val_reg_l2_loss: 0.0808 - val_loss: 0.2465\n"
     ]
    }
   ],
   "source": [
    "from tf2 import train\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "config.batch_size = 4\n",
    "tr_steps_per_epoch = 8000//config.batch_size # batch_size에 따른 epoch 당 train 데이터 수\n",
    "val_steps_per_epoch = 2000//config.batch_size # batch_size에 따른 epoch 당 val 데이터 수\n",
    "print('tr_steps_per_epoch:', tr_steps_per_epoch, 'val_steps_per_epoch:', val_steps_per_epoch)\n",
    "\n",
    "# wandb loss값 저장\n",
    "class CustomHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        wandb.log(logs)\n",
    "\n",
    "custom_hist = CustomHistory()\n",
    "custom_hist.init()\n",
    "\n",
    "val_dataset = get_dataset(False, config)\n",
    "\n",
    "# pretrain_ckpt를 가져올지 이전의 ckpt를 가져올지 정함.\n",
    "ckpt_path = tf.train.latest_checkpoint(TRAIN_CFG.model_dir)\n",
    "if config.pretrain_or_ckpt == 'True':\n",
    "    initial_epoch = 0\n",
    "else:\n",
    "    initial_epoch = int(os.path.basename(ckpt_path).split('-')[1])\n",
    "    \n",
    "# 학습 시작\n",
    "model.fit(\n",
    "    get_dataset(True, config),\n",
    "    epochs=config.num_epochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    steps_per_epoch=tr_steps_per_epoch,\n",
    "    callbacks=[train_lib.get_callbacks(config.as_dict(), val_dataset),custom_hist],\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=val_steps_per_epoch)\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d136dbf6b15a1dcd03292ef6a9edc132f105406e4aeaab89de03fb175e670c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
