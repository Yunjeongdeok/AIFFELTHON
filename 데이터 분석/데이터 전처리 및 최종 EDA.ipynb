{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971f6e04",
   "metadata": {},
   "source": [
    "# 🎈분석 결과를 토대로 자율주행에 적합한 데이터 선별\n",
    "- 학습 시간을 고려하여 데이터를 최대 1만 장, 이미지 사이즈(960,512)를 사용하기로 함. (데이터 1000장, 이미지 사이즈:(1920,1024), epoch:100, GPU:v100, 학습 시간: 6시간)\n",
    "\n",
    "## 1. 객체 분포를 기준으로 1만 장 선별\n",
    "   - 분류학습을 위해서는 객체의 수가 많을수록 좋다고 생각하였고 그래서 적은 객체를 모두 포함할 수 있는 방향으로 데이터를 우선 선별하여 객체가 최대한 고르게 분포하도록 하였음.\n",
    "   \n",
    "## 2. 전, 후, 측 방 데이터를 기준으로 1만 장 선별\n",
    "   - 학습 시간을 알아보기 위한 yolov7 학습 결과에서 분류 학습 시에 전방 이미지가 많이 들어가서 차량의 후방이미지에 대한 분류는 잘 이루어졌지만, 전방 이미지를 잘 분류하지 못하는 것을 확인하였고 그를 토대로 객체의 모든 부분을 골고루 학습시키기 위해 후, 측방을 다 포함하고 나머지를 전방 이미지로 하여 1만 장을 선별함.\n",
    "   - 또한 우리가 분류할 객체를 팀 간 협의하여 4개로 수정 (car, truck, bus, pedestrian(adult, child, specialclothes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "img_path = sorted(glob('/aiffel/aiffel/aiffelthon/random_1000/*.png'))\n",
    "json_path = sorted(glob('/aiffel/aiffel/aiffelthon/random_1000/*.json'))\n",
    "\n",
    "#  새로운 json을 저장할 폴더 생성\n",
    "# !mkdir -p /aiffel/aiffel/aiffelthon/new_json\n",
    "# 이미지, 라벨 순서 다른게 있는지 확인\n",
    "for i, j in zip(img_path, json_path):\n",
    "    if i.split('/')[-1][:-4]!=j.split('/')[-1][:-13]:\n",
    "        print(i.split('/')[-1][:-4] , j.split('/')[-1][:-13])\n",
    "\n",
    "    \n",
    "# 데이터 만들기\n",
    "new_json = {}\n",
    "for i, j in zip(img_path, json_path):\n",
    "    with open(j, 'r')as f:# json 읽어오기\n",
    "        json_ = json.load(f)\n",
    "        \n",
    "    # 새로운 json에 meta정보 추가\n",
    "    new_json = {'filename': json_['filename'], 'weather': json_['weather'], 'illumination_status': json_['illumination_status'],\\\n",
    "                'road_status': json_['road_status'],'crowd_level': json_['crowd_level'], 'sensor_status': json_['sensor_status']}\n",
    "    \n",
    "    # 새로운 json에 annotation정보 추가\n",
    "    anno = []\n",
    "    for k in json_['annotations']:\n",
    "        # 가짜 이미지가 아니고\n",
    "        if k['isfake'] == 0:    \n",
    "            # 클래스가 내가 원하는 클래스이면 새로운 json에 추가\n",
    "            bbox = k['points']\n",
    "            # bbox 정규화\n",
    "            norm_bbox = [[bbox[0][0]/1920, bbox[0][1]/1024],[bbox[1][0]/1920, bbox[1][1]/1024],\\\n",
    "                         [bbox[2][0]/1920, bbox[2][1]/1024],[bbox[3][0]/1920, bbox[3][1]/1024]]\n",
    "            if k['attribute'] == 'car':\n",
    "                anno.append({'id': k['id'], 'type': k['type'], 'attribute': 'car', 'points': norm_bbox,\\\n",
    "                         'occlusion': k['occlusion'], 'truncation':  k['truncation'], 'scenario':  k['scenario'],\\\n",
    "                            'isfake': k['isfake'],'ismask': k['ismask'], 'area':  k['area']})\n",
    "\n",
    "            elif k['attribute'] in ['adult','specialclothes','child']:\n",
    "                anno.append({'id': k['id'], 'type': k['type'], 'attribute': 'pedestrian', 'points': norm_bbox,\\\n",
    "                         'occlusion': k['occlusion'], 'truncation':  k['truncation'], 'scenario':  k['scenario'],\\\n",
    "                             'isfake': k['isfake'],'ismask': k['ismask'], 'area':  k['area']})\n",
    "\n",
    "            elif k['attribute'] in ['truck_s','truck_l']:\n",
    "                anno.append({'id': k['id'], 'type': k['type'], 'attribute': 'truck', 'points': norm_bbox,\\\n",
    "                         'occlusion': k['occlusion'], 'truncation':  k['truncation'], 'scenario': k['scenario'],\\\n",
    "                             'isfake': k['isfake'],'ismask': k['ismask'], 'area':  k['area']})\n",
    "\n",
    "            elif k['attribute'] in ['bus_l','bus_s']:\n",
    "                anno.append({'id': k['id'], 'type': k['type'], 'attribute':  'bus', 'points': norm_bbox,\\\n",
    "                         'occlusion': k['occlusion'], 'truncation':  k['truncation'], 'scenario':  k['scenario'],\\\n",
    "                             'isfake': k['isfake'],'ismask': k['ismask'], 'area':  k['area']})\n",
    "                \n",
    "    #  이미지에 원하는 객체가 아무것도 없을때 확인용\n",
    "#     if anno == []:\n",
    "#         print(\"이미지에 원하는 객체가 없습니다.\")\n",
    "#         print(*[(f['attribute'],f['isfake']) for f in json_['annotations']], '\\n')\n",
    "#         plt.imshow(cv2.cvtColor(cv2.imread(i), cv2.COLOR_BGR2RGB))\n",
    "#         plt.show()\n",
    "        \n",
    "    # 새로운 json 완성    \n",
    "    new_json['annotations'] = anno\n",
    "    \n",
    "    new_json_path = '/aiffel/aiffel/aiffelthon/new_json/'\n",
    "    # 전처리 후 이미지에 객체가 하나라도 있으면 new_json 저장\n",
    "    if new_json['annotations'] !=[]:\n",
    "#         print( new_json_path+new_json['filename'][:-4]+'.json')\n",
    "        with open(new_json_path+new_json['filename'][:-4]+'.json', 'w')as f:\n",
    "            json.dump(new_json,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24fd2e",
   "metadata": {},
   "source": [
    "## 최종 선별한 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일 생성\n",
    "import pandas as pd\n",
    "jsons = sorted(glob('/aiffel/aiffel/datasets/final_dataset/labels/*.json'))\n",
    "\n",
    "meta = pd.DataFrame()\n",
    "anno = pd.DataFrame()\n",
    "for i in jsons:\n",
    "\n",
    "    with open(i, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "    annot = data['annotations']\n",
    "    \n",
    "    for i in range(len(annot)):\n",
    "        annot[i]['filename'] = data['filename']\n",
    "    data.pop('annotations')\n",
    "    annot = pd.DataFrame(annot)\n",
    "    meta = meta.append([data], ignore_index=True)\n",
    "    anno = pd.concat([anno, annot])\n",
    "\n",
    "meta.to_csv('final_meta.csv', encoding = 'utf-8',index = False)\n",
    "anno.to_csv('final_anno.csv', encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "meta = pd.read_csv('final_meta.csv')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno =  pd.read_csv('final_anno.csv')\n",
    "anno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c51e24",
   "metadata": {},
   "source": [
    "## 📈meta 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('coolwarm', 10)\n",
    "plot_list = ['weather','sensor_status','crowd_level','illumination_status']\n",
    "plt.figure(figsize=(30, 20))\n",
    "# plt.subplots(constrained_layout=True)\n",
    "for i in range(len(plot_list)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    ax = sns.countplot(x = plot_list[i], data = meta, palette = palette)\n",
    "    plt.xlabel(plot_list[i],fontsize = 18)\n",
    "    plt.ylabel('Rates',fontsize = 18)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width()/2., height+5, height, ha = 'center', size = 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a947d8",
   "metadata": {},
   "source": [
    "## 📉annotations 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_list = ['attribute','occlusion','truncation','isfake']\n",
    "plt.figure(figsize=(30, 20))\n",
    "# plt.subplots(constrained_layout=True)\n",
    "for i in range(len(plot_list)):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    ax = sns.countplot(x = plot_list[i], data = anno, palette = palette)\n",
    "    plt.xlabel(plot_list[i],fontsize = 15)\n",
    "    plt.ylabel('Rates',fontsize = 15)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width()/2., height+5, height, ha = 'center', size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848d052",
   "metadata": {},
   "source": [
    "## 🎈전방이미지와 후,측방 이미지 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73da61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rr = [i for i in meta['filename'] if i[14:16]!='FR']# 후,측방 이미지 수      \n",
    "fr = [i for i in meta['filename'] if i[14:16]=='FR'] # 전방 이미지 수\n",
    "len(fr), len(rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676533f",
   "metadata": {},
   "source": [
    "## 📝최종 선별한 데이터 분석 결과\n",
    "- 우리가 원했던 후, 측방 이미지를 최대한 포함한 결과 후, 측방 이미지 4454장을 수집할 수 있었다.\n",
    "- 라벨링도 4가지(car, truck, bus, pedestrian) 클래스에 대해 잘 분리된 것을 확인할 수 있다. \n",
    "- isfake에 대해서도 가짜 이미지를 모두 빼는 게 좋겠다는 피드백을 수용하여 모두 제거하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e9128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d136dbf6b15a1dcd03292ef6a9edc132f105406e4aeaab89de03fb175e670c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
